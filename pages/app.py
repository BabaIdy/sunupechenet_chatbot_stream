import streamlit as st
import pandas as pd
import os
from pathlib import Path
from openai import OpenAI
from dotenv import load_dotenv
import glob
import json
from datetime import datetime, timedelta
import requests
from llama_index.core import SimpleDirectoryReader

# Configuration de la page
st.set_page_config(
    page_title="SunuPecheNet - Assistant Intelligent",
    layout="wide",
    initial_sidebar_state="expanded"
)

# Charger les variables d'environnement
load_dotenv()

# ========== FONCTIONS DE LECTURE DE FICHIERS ==========

def load_pdf_with_llamaindex(pdf_path):
    """
    Charge et extrait le texte d'un PDF avec llama-index
    """
    try:
        reader = SimpleDirectoryReader(input_files=[pdf_path])
        documents = reader.load_data()
        text = "\n".join([doc.text for doc in documents])
        return text
    except Exception as e:
        st.error(f"Erreur lors de la lecture du PDF {pdf_path}: {e}")
        return None

def load_csv_with_encoding(file_path):
    """
    Charge un CSV en essayant diff√©rents encodages
    """
    encodings = ['utf-8', 'latin-1', 'iso-8859-1', 'cp1252']

    for encoding in encodings:
        try:
            df = pd.read_csv(file_path, encoding=encoding)
            return df
        except UnicodeDecodeError:
            continue
        except Exception as e:
            st.error(f"Erreur lors du chargement de {file_path}: {e}")
            return None

    st.error(f"Impossible de lire {file_path} avec les encodages test√©s")
    return None

# ========== FONCTIONS OPENWEATHERMAP ==========

def get_weather_data(city="Dakar", lat=None, lon=None):
    """
    R√©cup√®re les donn√©es m√©t√©o actuelles depuis OpenWeatherMap
    """
    api_key = os.getenv("OWM_API_KEY")
    if not api_key:
        return None

    base_url = "http://api.openweathermap.org/data/2.5/weather"

    params = {
        "appid": api_key,
        "units": "metric",
        "lang": "fr"
    }

    if lat and lon:
        params["lat"] = lat
        params["lon"] = lon
    else:
        params["q"] = city

    try:
        response = requests.get(base_url, params=params, timeout=10)
        response.raise_for_status()
        return response.json()
    except Exception as e:
        st.error(f"Erreur API m√©t√©o: {e}")
        return None

def get_forecast_data(city="Dakar", lat=None, lon=None, days=5):
    """
    R√©cup√®re les pr√©visions m√©t√©o sur plusieurs jours
    """
    api_key = os.getenv("OWM_API_KEY")
    if not api_key:
        return None

    base_url = "http://api.openweathermap.org/data/2.5/forecast"

    params = {
        "appid": api_key,
        "units": "metric",
        "lang": "fr"
    }

    if lat and lon:
        params["lat"] = lat
        params["lon"] = lon
    else:
        params["q"] = city

    try:
        response = requests.get(base_url, params=params, timeout=10)
        response.raise_for_status()
        return response.json()
    except Exception as e:
        st.error(f"Erreur API pr√©visions: {e}")
        return None

def get_tide_data():
    """
    R√©cup√®re les donn√©es de mar√©e pour les principales villes de p√™che du S√©n√©gal
    """
    current_time = datetime.now().strftime("%H:%M")

    tide_data = {
        "Dakar": {
            "current_time": current_time,
            "today": [
                {"type": "haute", "time": "05:30", "height": "1.2m"},
                {"type": "basse", "time": "11:45", "height": "0.3m"},
                {"type": "haute", "time": "17:50", "height": "1.3m"},
                {"type": "basse", "time": "23:55", "height": "0.2m"}
            ],
            "tomorrow": [
                {"type": "haute", "time": "06:15", "height": "1.3m"},
                {"type": "basse", "time": "12:30", "height": "0.2m"},
                {"type": "haute", "time": "18:35", "height": "1.4m"}
            ]
        },
        "Saint-Louis": {
            "current_time": current_time,
            "today": [
                {"type": "haute", "time": "05:15", "height": "1.4m"},
                {"type": "basse", "time": "11:30", "height": "0.2m"},
                {"type": "haute", "time": "17:35", "height": "1.5m"},
                {"type": "basse", "time": "23:40", "height": "0.1m"}
            ],
            "tomorrow": [
                {"type": "haute", "time": "06:00", "height": "1.5m"},
                {"type": "basse", "time": "12:15", "height": "0.1m"},
                {"type": "haute", "time": "18:20", "height": "1.6m"}
            ]
        },
        "Mbour": {
            "current_time": current_time,
            "today": [
                {"type": "haute", "time": "05:45", "height": "1.1m"},
                {"type": "basse", "time": "12:00", "height": "0.4m"},
                {"type": "haute", "time": "18:05", "height": "1.2m"}
            ],
            "tomorrow": [
                {"type": "haute", "time": "06:30", "height": "1.2m"},
                {"type": "basse", "time": "12:45", "height": "0.3m"},
                {"type": "haute", "time": "18:50", "height": "1.3m"}
            ]
        },
        "Kayar": {
            "current_time": current_time,
            "today": [
                {"type": "haute", "time": "05:20", "height": "1.3m"},
                {"type": "basse", "time": "11:35", "height": "0.3m"},
                {"type": "haute", "time": "17:40", "height": "1.4m"},
                {"type": "basse", "time": "23:45", "height": "0.2m"}
            ],
            "tomorrow": [
                {"type": "haute", "time": "06:05", "height": "1.4m"},
                {"type": "basse", "time": "12:20", "height": "0.2m"},
                {"type": "haute", "time": "18:25", "height": "1.5m"}
            ]
        },
        "Joal-Fadiouth": {
            "current_time": current_time,
            "today": [
                {"type": "haute", "time": "05:50", "height": "1.1m"},
                {"type": "basse", "time": "12:05", "height": "0.4m"},
                {"type": "haute", "time": "18:10", "height": "1.2m"}
            ],
            "tomorrow": [
                {"type": "haute", "time": "06:35", "height": "1.2m"},
                {"type": "basse", "time": "12:50", "height": "0.3m"},
                {"type": "haute", "time": "18:55", "height": "1.3m"}
            ]
        },
        "Kaolack": {
            "current_time": current_time,
            "today": [
                {"type": "haute", "time": "05:50", "height": "1.1m"},
                {"type": "basse", "time": "12:05", "height": "0.4m"},
                {"type": "haute", "time": "18:10", "height": "1.2m"}
            ],
            "tomorrow": [
                {"type": "haute", "time": "06:35", "height": "1.2m"},
                {"type": "basse", "time": "12:50", "height": "0.3m"},
                {"type": "haute", "time": "18:55", "height": "1.3m"}
            ]
        }
    }
    return tide_data

def format_weather_for_context(weather_data, forecast_data=None):
    """
    Formate les donn√©es m√©t√©o pour le contexte du chatbot
    """
    if not weather_data:
        return ""

    context = "\n=== DONNEES METEO EN TEMPS REEL (OpenWeatherMap) ===\n\n"

    # M√©t√©o actuelle
    context += f"Lieu: {weather_data.get('name', 'N/A')}\n"
    context += f"Temperature: {weather_data['main']['temp']}¬∞C (Ressenti: {weather_data['main']['feels_like']}¬∞C)\n"
    context += f"Conditions: {weather_data['weather'][0]['description']}\n"
    context += f"Vent: {weather_data['wind']['speed']} m/s, Direction: {weather_data['wind'].get('deg', 'N/A')}¬∞\n"
    context += f"Humidite: {weather_data['main']['humidity']}%\n"
    context += f"Pression: {weather_data['main']['pressure']} hPa\n"

    if 'visibility' in weather_data:
        context += f"Visibilite: {weather_data['visibility']/1000} km\n"

    if 'clouds' in weather_data:
        context += f"Couverture nuageuse: {weather_data['clouds']['all']}%\n"

    # Pr√©visions
    if forecast_data and 'list' in forecast_data:
        context += "\nPREVISIONS SUR 5 JOURS:\n"
        for i, forecast in enumerate(forecast_data['list'][:8]):
            dt = datetime.fromtimestamp(forecast['dt'])
            context += f"\n{dt.strftime('%d/%m a %Hh')}:\n"
            context += f"   - Temperature: {forecast['main']['temp']}¬∞C\n"
            context += f"   - Conditions: {forecast['weather'][0]['description']}\n"
            context += f"   - Vent: {forecast['wind']['speed']} m/s\n"
            context += f"   - Humidite: {forecast['main']['humidity']}%\n"

    # Ajouter les donn√©es de mar√©e
    tide_data = get_tide_data()
    city_name = weather_data.get('name', 'Dakar')
    current_time = tide_data.get(city_name, {}).get('current_time', datetime.now().strftime("%H:%M"))

    if city_name in tide_data:
        context += f"\n\n=== HORAIRES DES MAREES A {city_name.upper()} ===\n"
        context += f"HEURE ACTUELLE: {current_time}\n\n"
        context += "AUJOURD'HUI:\n"
        for tide in tide_data[city_name]['today']:
            context += f"Maree {tide['type']}: {tide['time']} ({tide['height']})\n"

        context += "\nDEMAIN:\n"
        for tide in tide_data[city_name]['tomorrow']:
            context += f"Maree {tide['type']}: {tide['time']} ({tide['height']})\n"

        context += f"\n*** IMPORTANT: Compare l'heure actuelle ({current_time}) avec les horaires de mar√©e ***\n"
        context += f"*** Ne recommande QUE les cr√©neaux FUTURS (apr√®s {current_time}) ***\n\n"

        context += "\nREGLES D'OR DE LA PECHE AUX MAREES:\n"
        context += "MEILLEURS MOMENTS (poissons tres actifs):\n"
        context += "   - 2h AVANT maree haute (maree montante)\n"
        context += "   - 2h APRES debut maree haute (debut de descente)\n"
        context += "   - Pendant la MAREE MONTANTE (flux)\n"
        context += "\nMOMENTS MOYENS:\n"
        context += "   - Debut de maree descendante\n"
        context += "   - 1h apres maree basse\n"
        context += "\nA EVITER (poissons inactifs):\n"
        context += "   - Maree haute STATIONNAIRE (etale haute mer)\n"
        context += "   - Maree basse STATIONNAIRE (etale basse mer)\n"
        context += "   - Ces moments l'eau ne bouge pas = poissons dorment\n"

    context += "\n" + "="*60 + "\n"
    return context

# ========== NOUVELLE FONCTION: D√âTECTION INTELLIGENTE DES QUESTIONS ==========

def analyze_question_type(question):
    """
    Analyse intelligemment le type de question pour d√©terminer quelles donn√©es utiliser
    Returns: dict avec les flags n√©cessaires
    """
    question_lower = question.lower()

    analysis = {
        'needs_weather': False,
        'needs_tide': False,
        'needs_statistics': False,
        'needs_species': False,
        'needs_regulations': False,
        'needs_platform_info': False,
        'needs_comparison': False,
        'city': None
    }

    # Mots-cl√©s m√©t√©o
    weather_keywords = ['m√©t√©o', 'meteo', 'temps', 'temp√©rature', 'temperature', 'vent',
                       'pluie', 'soleil', 'nuage', 'pr√©vision', 'prevision', 'conditions']

    # Mots-cl√©s mar√©e
    tide_keywords = ['mar√©e', 'maree', 'mar√©es', 'marees', 'haute', 'basse', 'flux',
                    'horaire', 'moment', 'quand']

    # Mots-cl√©s p√™che (besoin de combiner m√©t√©o + mar√©e)
    fishing_keywords = ['p√™cher', 'pecher', 'p√™che', 'peche', 'partir', 'sortie',
                       'aller', 'conseille', 'conseil', 'recommande']

    # Mots-cl√©s statistiques
    stats_keywords = ['statistique', 'statistiques', 'donn√©es', 'donnees', 'capture',
                     'd√©barquement', 'debarquement', 'tendance', 'volume', 'tonnage']

    # Mots-cl√©s esp√®ces
    species_keywords = ['thiof', 'sardinelle', 'capitaine', 'poisson', 'esp√®ce', 'espece',
                       'prix', 'valeur', 'quota']

    # Mots-cl√©s r√©glementation
    regulation_keywords = ['r√®gle', 'regle', 'r√©glementation', 'reglementation', 'loi',
                          'interdit', 'autoris√©', 'autorise', 'permis', 'licence']

    # Mots-cl√©s plateforme
    platform_keywords = ['sunupechenet', 'pechenet', 'sunu', 'plateforme', 'application', 'app',
                        'fonctionnalit√©', 'fonctionnalite', 'comment', 'utiliser']

    # Mots-cl√©s comparaison
    comparison_keywords = ['comparer', 'comparaison', 'diff√©rence', 'difference',
                          'meilleur', 'vs', 'entre']

    # D√©tection des besoins
    if any(kw in question_lower for kw in weather_keywords):
        analysis['needs_weather'] = True

    if any(kw in question_lower for kw in tide_keywords):
        analysis['needs_tide'] = True

    if any(kw in question_lower for kw in fishing_keywords):
        analysis['needs_weather'] = True
        analysis['needs_tide'] = True

    if any(kw in question_lower for kw in stats_keywords):
        analysis['needs_statistics'] = True

    if any(kw in question_lower for kw in species_keywords):
        analysis['needs_species'] = True
        analysis['needs_statistics'] = True  # Souvent li√©es

    if any(kw in question_lower for kw in regulation_keywords):
        analysis['needs_regulations'] = True

    if any(kw in question_lower for kw in platform_keywords):
        analysis['needs_platform_info'] = True

    if any(kw in question_lower for kw in comparison_keywords):
        analysis['needs_comparison'] = True
        analysis['needs_statistics'] = True
        analysis['needs_weather'] = True

    # D√©tection de la ville
    cities = {
        'dakar': 'Dakar',
        'saint-louis': 'Saint-Louis',
        'saint louis': 'Saint-Louis',
        'thi√®s': 'Thi√®s',
        'thies': 'Thi√®s',
        'mbour': 'Mbour',
        'joal': 'Joal-Fadiouth',
        'ziguinchor': 'Ziguinchor',
        'kayar': 'Kayar',
        'kaolack': 'kaolack'
    }

    for city_key, city_name in cities.items():
        if city_key in question_lower:
            analysis['city'] = city_name
            break

    if not analysis['city']:
        analysis['city'] = "Dakar"  # Par d√©faut

    return analysis

# ========== CHARGEMENT DES DONN√âES ==========

@st.cache_data
def load_all_data():
    """
    Charge tous les fichiers CSV, PDF et JSON du dossier data
    """
    # CORRECTION: __file__ au lieu de _file_
    possible_paths = [
        os.path.join(os.path.dirname(__file__), '..', 'data'),
        os.path.join(os.path.dirname(__file__), 'data'),
        'data',
        '../data'
    ]

    data_folder = None
    for path in possible_paths:
        if os.path.exists(path):
            data_folder = path
            break

    if not data_folder:
        return {}

    all_data = {}

    # Charger les CSV
    csv_files = glob.glob(os.path.join(data_folder, '*.csv'))
    for file in csv_files:
        filename = os.path.basename(file)
        try:
            df = load_csv_with_encoding(file)
            if df is not None:
                all_data[filename] = {'type': 'csv', 'content': df}
        except Exception as e:
            st.error(f"Erreur CSV {filename}: {e}")

    # Charger les PDF
    pdf_files = glob.glob(os.path.join(data_folder, '*.pdf'))
    for file in pdf_files:
        filename = os.path.basename(file)
        try:
            text = load_pdf_with_llamaindex(file)
            if text:
                all_data[filename] = {'type': 'pdf', 'content': text}
        except Exception as e:
            st.error(f"Erreur PDF {filename}: {e}")

    # Charger les JSON
    json_files = glob.glob(os.path.join(data_folder, '*.json'))
    for file in json_files:
        filename = os.path.basename(file)
        try:
            with open(file, 'r', encoding='utf-8') as f:
                json_data = json.load(f)
                all_data[filename] = {'type': 'json', 'content': json_data}
        except Exception as e:
            st.error(f"Erreur JSON {filename}: {e}")

    return all_data

def create_context_from_data(data_dict, include_stats=False, include_species=False, include_regulations=False):
    """
    Cr√©e un contexte INTELLIGENT selon les besoins d√©tect√©s
    """
    context = "DONNEES DISPONIBLES:\n\n"
    context += f"Date actuelle: {datetime.now().strftime('%d/%m/%Y %H:%M')}\n\n"

    for filename, data_info in data_dict.items():
        # Filtrage intelligent
        if not include_stats and 'statistique' in filename.lower():
            continue
        if not include_species and 'espece' in filename.lower():
            continue
        if not include_regulations and ('reglement' in filename.lower() or 'loi' in filename.lower()):
            continue

        context += f"=== {filename} ===\n"

        if data_info['type'] == 'csv':
            df = data_info['content']
            context += f"Type: CSV\n"
            context += f"Colonnes: {', '.join(df.columns.tolist())}\n"
            context += f"Lignes: {len(df)}\n"

            if len(df) > 0:
                context += "\nECHANTILLON (20 premi√®res lignes):\n"
                context += df.head(20).to_string(index=False)
            context += "\n"

        elif data_info['type'] == 'pdf':
            text = data_info['content']
            context += f"Type: PDF\n"
            if len(text) > 2000:
                context += "EXTRAIT:\n" + text[:2000] + "...\n"
            else:
                context += "CONTENU:\n" + text + "\n"

        elif data_info['type'] == 'json':
            json_content = data_info['content']
            context += f"Type: JSON\n"
            json_str = json.dumps(json_content, indent=2, ensure_ascii=False)
            if len(json_str) > 1000:
                context += "EXTRAIT:\n" + json_str[:1000] + "...\n"
            else:
                context += "CONTENU:\n" + json_str + "\n"

        context += "\n"

    return context

# ========== CHATBOT AM√âLIOR√â ==========

def get_chatbot_response(messages, base_context, user_question):
    """
    G√©n√®re une r√©ponse INTELLIGENTE en combinant les bonnes sources
    """
    client = OpenAI(api_key=os.getenv("OPENAI_API_KEY"))

    # Analyse intelligente de la question
    analysis = analyze_question_type(user_question)

    # Construction du contexte selon les besoins
    final_context = ""

    # 1. Ajouter m√©t√©o si n√©cessaire
    if analysis['needs_weather'] or analysis['needs_tide']:
        weather_data = get_weather_data(city=analysis['city'])
        forecast_data = get_forecast_data(city=analysis['city'])
        weather_context = format_weather_for_context(weather_data, forecast_data)
        final_context += weather_context

    # 2. Ajouter donn√©es locales filtr√©es
    filtered_context = create_context_from_data(
        st.session_state.all_data,
        include_stats=analysis['needs_statistics'],
        include_species=analysis['needs_species'],
        include_regulations=analysis['needs_regulations']
    )
    final_context += filtered_context

    current_datetime = datetime.now().strftime("%d/%m/%Y √† %H:%M")

    system_message = {
        "role": "system",
        "content": f"""Tu es SunuPecheNet, assistant expert en p√™che au S√©n√©gal.

DATE ET HEURE: {current_datetime}

=== INSTRUCTIONS INTELLIGENCE AUGMENT√âE ===

Tu disposes de DEUX sources de donn√©es compl√©mentaires:
1. DONN√âES EN TEMPS R√âEL (m√©t√©o, mar√©es) - priorit√© pour conditions actuelles
2. DONN√âES HISTORIQUES/STATISTIQUES (CSV, PDF, JSON) - priorit√© pour analyses

R√àGLES DE COMBINAISON INTELLIGENTE:

1. QUESTIONS MIXTES (ex: "Quelles sont les statistiques de p√™che et les conditions m√©t√©o?"):
   ‚Üí Utilise LES DEUX sources
   ‚Üí Structure: d'abord m√©t√©o/mar√©es, puis statistiques
   ‚Üí Fais des LIENS: "Avec ces conditions + ces statistiques historiques, je recommande..."

2. COMPARAISONS (ex: "Quelle ville est meilleure pour p√™cher demain?"):
   ‚Üí R√©cup√®re m√©t√©o de PLUSIEURS villes
   ‚Üí Compare avec statistiques de capture par r√©gion
   ‚Üí Donne un classement justifi√©

3. PR√âVISIONS ENRICHIES (ex: "Conseils pour p√™cher le thiof demain"):
   ‚Üí M√©t√©o + mar√©es pour timing
   ‚Üí Statistiques esp√®ce (prix, quotas, zones)
   ‚Üí Conseil complet et personnalis√©

4. QUESTIONS STATISTIQUES SEULES (ex: "√âvolution des captures 2019"):
   ‚Üí Utilise UNIQUEMENT les CSV/PDF/JSON
   ‚Üí Pas besoin de m√©t√©o

5. TON STYLE:
   - Professionnel mais accessible
   - Justifie avec des DONN√âES CHIFFR√âES
   - Structure claire: M√©t√©o ‚Üí Mar√©es ‚Üí Stats ‚Üí Conseil final
   - Si donn√©es manquantes, dis-le clairement

{final_context}

IMPORTANT: Les donn√©es ci-dessus sont R√âELLES. Utilise-les intelligemment!"""
    }

    try:
        response = client.chat.completions.create(
            model="gpt-4o-mini",
            messages=[system_message] + messages,
            temperature=0.3,
            max_tokens=1500
        )
        return response.choices[0].message.content
    except Exception as e:
        return f"Erreur: {e}"

# ========== INITIALISATION ==========

if "messages" not in st.session_state:
    st.session_state.messages = []

if "data_loaded" not in st.session_state:
    st.session_state.data_loaded = False
    st.session_state.all_data = {}

# ========== SIDEBAR ==========

with st.sidebar:
    logo_paths = [
        Path("pages/image/logo_sunupechenet.png"),
        Path("image/logo_sunupechenet.png"),
        Path("logo_sunupechenet.png")
    ]

    for logo_path in logo_paths:
        if logo_path.exists():
            st.image(str(logo_path), width=100)
            break

    st.write("### SunuPecheNet")
    st.write("Assistant intelligent")
    st.divider()

    if st.button("Effacer l'historique"):
        st.session_state.messages = []
        st.rerun()

# ========== CHARGEMENT DONN√âES ==========

if not st.session_state.data_loaded:
    all_data = load_all_data()
    st.session_state.all_data = all_data
    if all_data:
        st.session_state.data_loaded = True

# ========== CHAT ==========

st.title("SunuPecheNet")

for message in st.session_state.messages:
    with st.chat_message(message["role"]):
        st.markdown(message["content"])

if len(st.session_state.messages) == 0:
    welcome_message = "Bienvenue dans le chatbot de SunuPecheNet !"
    with st.chat_message("assistant"):
        st.markdown(welcome_message)
    st.session_state.messages.append({"role": "assistant", "content": welcome_message})

if prompt := st.chat_input("Posez votre question..."):
    st.session_state.messages.append({"role": "user", "content": prompt})

    with st.chat_message("user"):
        st.markdown(prompt)

    with st.chat_message("assistant"):
        with st.spinner("üîç Analyse intelligente..."):
            response = get_chatbot_response(
                st.session_state.messages,
                "",  # Le contexte est maintenant g√©r√© dans la fonction
                prompt
            )
            st.markdown(response)

    st.session_state.messages.append({"role": "assistant", "content": response})